{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SchNet S2EF training example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to demonstrate some of the basics of the Open Catalyst Project's (OCP) codebase and data. In this example, we will train a schnet model for predicting the energy and forces of a given structure (S2EF task). First, ensure you have installed the OCP ocp repo and all the dependencies according to the [README](https://github.com/Open-Catalyst-Project/ocp/blob/master/README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer: This notebook is for tutorial purposes, it is unlikely it will be practical to train baseline models on our larger datasets using this format. As a next step, we recommend trying the command line examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Downloads\\Train_thử\\mace-ocp\\ocpmodels\\models\\scn\\spherical_harmonics.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  _Jd = torch.load(os.path.join(os.path.dirname(__file__), \"Jd.pt\"))\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import os\n",
    "sys.path.append(r\"D:\\Train_thử\\fairchem-tio2-s2ef\")\n",
    "\n",
    "from ocpmodels.trainers import ForcesTrainer\n",
    "from ocpmodels import models\n",
    "from ocpmodels.common import logger\n",
    "from ocpmodels.common.utils import setup_logging\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# a simple sanity check that a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"True\")\n",
    "else:\n",
    "    print(\"False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The essential steps for training an OCP model\n",
    "\n",
    "1) Download data\n",
    "\n",
    "2) Preprocess data (if necessary)\n",
    "\n",
    "3) Define or load a configuration (config), which includes the following\n",
    "   \n",
    "   - task\n",
    "   - model\n",
    "   - optimizer\n",
    "   - dataset\n",
    "   - trainer\n",
    "\n",
    "4) Train\n",
    "\n",
    "5) Depending on the model/task there might be intermediate relaxation step\n",
    "\n",
    "6) Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This examples uses the LMDB generated from the following [tutorial](http://laikapack.cheme.cmu.edu/notebook/open-catalyst-project/mshuaibi/notebooks/projects/ocp/docs/source/tutorials/lmdb_dataset_creation.ipynb). Please run that notebook before moving on. Alternatively, if you have other LMDBs available you may specify that instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to your local lmdb directory\n",
    "# train_src = \"s2ef\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\envs\\tio2-s2ef\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3550: UserWarning: TrajectoryLmdbDataset is deprecated and will be removed in the future.Please use 'LmdbDataset' instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from ocpmodels.datasets import TrajectoryLmdbDataset\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "train_src = \"s2ef\"\n",
    "\n",
    "train_dataset = TrajectoryLmdbDataset({\"src\": train_src})\n",
    "\n",
    "energies = []\n",
    "for data in train_dataset:\n",
    "  energies.append(data.y)\n",
    "\n",
    "mean = np.mean(energies)\n",
    "stdev = np.std(energies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will explicitly define the config; however, a set of default config files exists in the config folder of this repository. Default config yaml files can easily be loaded with the `build_config` util (found in `ocp/ocpmodels/common/utils.py`). Loading a yaml config is preferrable when launching jobs from the command line. We have included our best models' config files [here](https://github.com/Open-Catalyst-Project/ocp/tree/master/configs/s2ef)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = {\n",
    "    'dataset': 'trajectory_lmdb', # dataset used for the S2EF task\n",
    "    'description': 'Regressing to energies and forces for DFT trajectories from OCP',\n",
    "    'type': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'labels': ['potential energy'],\n",
    "    'grad_input': 'atomic forces',\n",
    "    'train_on_free_atoms': True,\n",
    "    'eval_on_free_atoms': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model** - SchNet for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {\n",
    "    'name': 'gemnet_t',\n",
    "    \"num_spherical\": 7,\n",
    "    \"num_radial\": 128,\n",
    "    \"num_blocks\": 3,\n",
    "    \"emb_size_atom\": 512,\n",
    "    \"emb_size_edge\": 512,\n",
    "    \"emb_size_trip\": 64,\n",
    "    \"emb_size_rbf\": 16,\n",
    "    \"emb_size_cbf\": 16,\n",
    "    \"emb_size_bil_trip\": 64,\n",
    "    \"num_before_skip\": 1,\n",
    "    \"num_after_skip\": 2,\n",
    "    \"num_concat\": 1,\n",
    "    \"num_atom\": 3,\n",
    "    \"cutoff\": 6.0,\n",
    "    \"max_neighbors\": 50,\n",
    "    \"rbf\": {\"name\": \"gaussian\"},\n",
    "    \"envelope\": {\n",
    "      \"name\": \"polynomial\",\n",
    "      \"exponent\": 5,\n",
    "    },\n",
    "    \"cbf\": {\"name\": \"spherical_harmonics\"},\n",
    "    \"extensive\": True,\n",
    "    \"otf_graph\": False,\n",
    "    \"output_init\": \"HeOrthogonal\",\n",
    "    \"activation\": \"silu\",\n",
    "    \"scale_file\": \"D:\\\\Train_thử\\\\fairchem-tio2-s2ef\\\\configs\\\\s2ef\\\\all\\\\gemnet\\\\scaling_factors\\\\gemnet-dT.json\",\n",
    "    \"direct_forces\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = {\n",
    "    'batch_size': 1,         # originally 32\n",
    "    'eval_batch_size': 1,    # originally 32\n",
    "    'num_workers': 0,\n",
    "    'lr_initial': 5.e-4,\n",
    "    'optimizer': 'AdamW',\n",
    "    'optimizer_params': {\"amsgrad\": True},\n",
    "    'scheduler': \"ReduceLROnPlateau\",\n",
    "    'mode': \"min\",\n",
    "    'factor': 0.8,\n",
    "    'patience': 3,\n",
    "    'max_epochs': 1,         # used for demonstration purposes\n",
    "    'force_coefficient': 100,\n",
    "    'ema_decay': 0.999,\n",
    "    'clip_grad_norm': 10,\n",
    "    'loss_energy': 'mae',\n",
    "    'loss_force': 'l2mae',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, `train_src` is used for all the train/val/test sets. Feel free to update with the actual S2EF val and test sets, but it does require additional downloads and preprocessing. If you desire to normalize your targets, `normalize_labels` must be set to `True` and corresponding `mean` and `stds` need to be specified. These values have been precomputed for you and can be found in any of the [`base.yml`](https://github.com/Open-Catalyst-Project/ocp/blob/master/configs/s2ef/20M/base.yml#L5-L9) config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset = [\n",
    "  {'src': train_src,\n",
    "   'normalize_labels': True,\n",
    "   \"target_mean\": mean,\n",
    "   \"target_std\": stdev,\n",
    "   \"grad_target_mean\": 0.0,\n",
    "   \"grad_target_std\": stdev\n",
    "   }, # train set \n",
    "  {'src': train_src},\n",
    "]\n",
    "\n",
    "# dataset = [\n",
    "# {'src': train_src, 'normalize_labels': False}, # train set \n",
    "# {'src': train_src}, # val set (optional)\n",
    "# {'src': train_src} # test set (optional - writes predictions to disk)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trainer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `ForcesTrainer` for the S2EF and IS2RS tasks, and the `EnergyTrainer` for the IS2RE task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amp: true\n",
      "cmd:\n",
      "  checkpoint_dir: ./checkpoints\\2026-01-24-15-32-00-S2EF-example\n",
      "  commit: 73d08e6\n",
      "  identifier: S2EF-example\n",
      "  logs_dir: ./logs\\tensorboard\\2026-01-24-15-32-00-S2EF-example\n",
      "  print_every: 5\n",
      "  results_dir: ./results\\2026-01-24-15-32-00-S2EF-example\n",
      "  seed: 0\n",
      "  timestamp_id: 2026-01-24-15-32-00-S2EF-example\n",
      "dataset:\n",
      "  grad_target_mean: 0.0\n",
      "  grad_target_std: !!python/object/apply:numpy._core.multiarray.scalar\n",
      "  - &id001 !!python/object/apply:numpy.dtype\n",
      "    args:\n",
      "    - f8\n",
      "    - false\n",
      "    - true\n",
      "    state: !!python/tuple\n",
      "    - 3\n",
      "    - <\n",
      "    - null\n",
      "    - null\n",
      "    - null\n",
      "    - -1\n",
      "    - -1\n",
      "    - 0\n",
      "  - !!binary |\n",
      "    mW8Ma6rdbEA=\n",
      "  normalize_labels: true\n",
      "  src: s2ef\n",
      "  target_mean: !!python/object/apply:numpy._core.multiarray.scalar\n",
      "  - *id001\n",
      "  - !!binary |\n",
      "    VN+db85fdsA=\n",
      "  target_std: !!python/object/apply:numpy._core.multiarray.scalar\n",
      "  - *id001\n",
      "  - !!binary |\n",
      "    mW8Ma6rdbEA=\n",
      "gpus: 0\n",
      "logger: tensorboard\n",
      "model: gemnet_t\n",
      "model_attributes:\n",
      "  activation: silu\n",
      "  cbf:\n",
      "    name: spherical_harmonics\n",
      "  cutoff: 6.0\n",
      "  direct_forces: true\n",
      "  emb_size_atom: 512\n",
      "  emb_size_bil_trip: 64\n",
      "  emb_size_cbf: 16\n",
      "  emb_size_edge: 512\n",
      "  emb_size_rbf: 16\n",
      "  emb_size_trip: 64\n",
      "  envelope:\n",
      "    exponent: 5\n",
      "    name: polynomial\n",
      "  extensive: true\n",
      "  max_neighbors: 50\n",
      "  num_after_skip: 2\n",
      "  num_atom: 3\n",
      "  num_before_skip: 1\n",
      "  num_blocks: 3\n",
      "  num_concat: 1\n",
      "  num_radial: 128\n",
      "  num_spherical: 7\n",
      "  otf_graph: false\n",
      "  output_init: HeOrthogonal\n",
      "  rbf:\n",
      "    name: gaussian\n",
      "  regress_forces: true\n",
      "  scale_file: configs/s2ef/all/gemnet/scaling_factors/gemnet-dT.json\n",
      "noddp: false\n",
      "optim:\n",
      "  batch_size: 1\n",
      "  clip_grad_norm: 10\n",
      "  ema_decay: 0.999\n",
      "  eval_batch_size: 1\n",
      "  factor: 0.8\n",
      "  force_coefficient: 100\n",
      "  loss_energy: mae\n",
      "  loss_force: l2mae\n",
      "  lr_initial: 0.0005\n",
      "  max_epochs: 1\n",
      "  mode: min\n",
      "  num_workers: 0\n",
      "  optimizer: AdamW\n",
      "  optimizer_params:\n",
      "    amsgrad: true\n",
      "  patience: 3\n",
      "  scheduler: ReduceLROnPlateau\n",
      "slurm: {}\n",
      "task:\n",
      "  dataset: trajectory_lmdb\n",
      "  description: Regressing to energies and forces for DFT trajectories from OCP\n",
      "  eval_on_free_atoms: true\n",
      "  grad_input: atomic forces\n",
      "  labels:\n",
      "  - potential energy\n",
      "  metric: mae\n",
      "  train_on_free_atoms: true\n",
      "  type: regression\n",
      "trainer: forces\n",
      "val_dataset:\n",
      "  src: s2ef\n",
      "\n",
      "2026-01-24 15:31:54 (INFO): Batch balancing is disabled for single GPU training.\n",
      "2026-01-24 15:31:54 (INFO): Batch balancing is disabled for single GPU training.\n",
      "2026-01-24 15:31:54 (INFO): Loading dataset: trajectory_lmdb\n",
      "2026-01-24 15:31:54 (INFO): Loading model: gemnet_t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Downloads\\Train_thử\\mace-ocp\\ocpmodels\\trainers\\base_trainer.py:154: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler() if amp else None\n",
      "c:\\Users\\admin\\anaconda3\\envs\\tio2-s2ef\\lib\\site-packages\\torch\\amp\\grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Scale file configs\\s2ef\\all\\gemnet\\scaling_factors\\gemnet-dT.json does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mForcesTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# copied for later use, not necessary in practice.\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43midentifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mS2EF-example\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# directory to save results if is_debug=False. Prediction files are saved here so be careful not to override!\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_debug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# if True, do not save checkpoint, logs, or results\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# is_vis=False,\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# random seed to use\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtensorboard\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# logger of choice (tensorboard and wandb supported)\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# use PyTorch Automatic Mixed Precision (faster training and less memory usage),\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\Downloads\\Train_thử\\mace-ocp\\ocpmodels\\trainers\\forces_trainer.py:88\u001b[0m, in \u001b[0;36mForcesTrainer.__init__\u001b[1;34m(self, task, model, dataset, optimizer, identifier, normalizer, timestamp_id, run_dir, is_debug, is_hpo, print_every, seed, logger, local_rank, amp, cpu, slurm, noddp)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     69\u001b[0m     task,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m     noddp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     87\u001b[0m ):\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43midentifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midentifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimestamp_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_debug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_debug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_hpo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_hpo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ms2ef\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mslurm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslurm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnoddp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoddp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\Downloads\\Train_thử\\mace-ocp\\ocpmodels\\trainers\\base_trainer.py:205\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, task, model, dataset, optimizer, identifier, normalizer, timestamp_id, run_dir, is_debug, is_hpo, print_every, seed, logger, local_rank, amp, cpu, name, slurm, noddp)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m distutils\u001b[38;5;241m.\u001b[39mis_master():\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mprint\u001b[39m(yaml\u001b[38;5;241m.\u001b[39mdump(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, default_flow_style\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator \u001b[38;5;241m=\u001b[39m Evaluator(task\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\admin\\Downloads\\Train_thử\\mace-ocp\\ocpmodels\\trainers\\base_trainer.py:214\u001b[0m, in \u001b[0;36mBaseTrainer.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_datasets()\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_task()\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_loss()\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_optimizer()\n",
      "File \u001b[1;32mc:\\Users\\admin\\Downloads\\Train_thử\\mace-ocp\\ocpmodels\\trainers\\base_trainer.py:369\u001b[0m, in \u001b[0;36mBaseTrainer.load_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    364\u001b[0m bond_feat_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_attributes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_gaussians\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m    366\u001b[0m )\n\u001b[0;32m    368\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loader \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader\n\u001b[1;32m--> 369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m registry\u001b[38;5;241m.\u001b[39mget_model_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])(\n\u001b[0;32m    370\u001b[0m     loader\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loader\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(loader\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m loader\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    375\u001b[0m     bond_feat_dim,\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_targets,\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_attributes\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    378\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m distutils\u001b[38;5;241m.\u001b[39mis_master():\n\u001b[0;32m    381\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    382\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    384\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\admin\\Downloads\\Train_thử\\mace-ocp\\ocpmodels\\models\\gemnet\\gemnet.py:261\u001b[0m, in \u001b[0;36mGemNetT.__init__\u001b[1;34m(self, num_atoms, bond_feat_dim, num_targets, num_spherical, num_radial, num_blocks, emb_size_atom, emb_size_edge, emb_size_trip, emb_size_rbf, emb_size_cbf, emb_size_bil_trip, num_before_skip, num_after_skip, num_concat, num_atom, regress_forces, direct_forces, cutoff, max_neighbors, rbf, envelope, cbf, extensive, otf_graph, use_pbc, output_init, activation, num_elements, scale_file)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mint_blocks \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModuleList(int_blocks)\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared_parameters \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    255\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_rbf3\u001b[38;5;241m.\u001b[39mlinear\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_blocks),\n\u001b[0;32m    256\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_cbf3\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_blocks),\n\u001b[0;32m    257\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_rbf_h\u001b[38;5;241m.\u001b[39mlinear\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_blocks),\n\u001b[0;32m    258\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_rbf_out\u001b[38;5;241m.\u001b[39mlinear\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_blocks \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    259\u001b[0m ]\n\u001b[1;32m--> 261\u001b[0m \u001b[43mload_scales_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\Downloads\\Train_thử\\mace-ocp\\ocpmodels\\modules\\scaling\\compat.py:55\u001b[0m, in \u001b[0;36mload_scales_compat\u001b[1;34m(module, scale_file)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_scales_compat\u001b[39m(\n\u001b[0;32m     53\u001b[0m     module: nn\u001b[38;5;241m.\u001b[39mModule, scale_file: Optional[Union[\u001b[38;5;28mstr\u001b[39m, ScaleDict]]\n\u001b[0;32m     54\u001b[0m ):\n\u001b[1;32m---> 55\u001b[0m     scale_dict \u001b[38;5;241m=\u001b[39m \u001b[43m_load_scale_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscale_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scale_dict:\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\Downloads\\Train_thử\\mace-ocp\\ocpmodels\\modules\\scaling\\compat.py:31\u001b[0m, in \u001b[0;36m_load_scale_dict\u001b[1;34m(scale_file)\u001b[0m\n\u001b[0;32m     29\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(scale_file)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScale file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m scale_dict: Optional[ScaleDict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Scale file configs\\s2ef\\all\\gemnet\\scaling_factors\\gemnet-dT.json does not exist."
     ]
    }
   ],
   "source": [
    "trainer = ForcesTrainer(\n",
    "    task=task,\n",
    "    model=copy.deepcopy(model), # copied for later use, not necessary in practice.\n",
    "    dataset=dataset,\n",
    "    optimizer=optimizer,\n",
    "    identifier=\"S2EF-example\",\n",
    "    run_dir=\"./\", # directory to save results if is_debug=False. Prediction files are saved here so be careful not to override!\n",
    "    is_debug=False, # if True, do not save checkpoint, logs, or results\n",
    "    # is_vis=False,\n",
    "    print_every=5,\n",
    "    seed=0, # random seed to use\n",
    "    logger=\"tensorboard\", # logger of choice (tensorboard and wandb supported)\n",
    "    local_rank=0,\n",
    "    amp=True, # use PyTorch Automatic Mixed Precision (faster training and less memory usage),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCPDataParallel(\n",
      "  (module): SchNetWrap(hidden_channels=1024, num_filters=256, num_interactions=3, num_gaussians=200, cutoff=6.0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(trainer.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Checkpoint\n",
    "Once training has completed a `Trainer` class, by default, is loaded with the best checkpoint as determined by training or validation (if available) metrics. To load a `Trainer` class directly with a pretrained model, specify the `checkpoint_path` as defined by your previously trained model (`checkpoint_dir`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./checkpoints/2021-09-04-08-51-28-SchNet-example/checkpoint.pt'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = os.path.join(trainer.config[\"cmd\"][\"checkpoint_dir\"], \"checkpoint.pt\")\n",
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amp: false\n",
      "cmd:\n",
      "  checkpoint_dir: ./checkpoints/2021-09-04-08-51-28-SchNet-example\n",
      "  commit: 98a06d8\n",
      "  identifier: SchNet-example\n",
      "  logs_dir: ./logs/tensorboard/2021-09-04-08-51-28-SchNet-example\n",
      "  print_every: 10\n",
      "  results_dir: ./results/2021-09-04-08-51-28-SchNet-example\n",
      "  seed: 0\n",
      "  timestamp_id: 2021-09-04-08-51-28-SchNet-example\n",
      "dataset:\n",
      "  normalize_labels: false\n",
      "  src: s2ef\n",
      "gpus: 1\n",
      "logger: tensorboard\n",
      "model: schnet\n",
      "model_attributes:\n",
      "  cutoff: 6.0\n",
      "  hidden_channels: 1024\n",
      "  num_filters: 256\n",
      "  num_gaussians: 200\n",
      "  num_interactions: 3\n",
      "optim:\n",
      "  batch_size: 16\n",
      "  eval_batch_size: 8\n",
      "  factor: 0.8\n",
      "  force_coefficient: 100\n",
      "  lr_initial: 0.0001\n",
      "  max_epochs: 1\n",
      "  mode: min\n",
      "  num_workers: 8\n",
      "  patience: 3\n",
      "  scheduler: ReduceLROnPlateau\n",
      "slurm: {}\n",
      "task:\n",
      "  dataset: trajectory_lmdb\n",
      "  description: Regressing to energies and forces for DFT trajectories from OCP\n",
      "  eval_on_free_atoms: true\n",
      "  grad_input: atomic forces\n",
      "  labels:\n",
      "  - potential energy\n",
      "  metric: mae\n",
      "  train_on_free_atoms: true\n",
      "  type: regression\n",
      "test_dataset:\n",
      "  src: s2ef\n",
      "val_dataset:\n",
      "  src: s2ef\n",
      "\n",
      "2021-09-04 08:51:51 (INFO): Loading dataset: trajectory_lmdb\n",
      "2021-09-04 08:51:51 (INFO): Loading model: schnet\n",
      "2021-09-04 08:51:51 (INFO): Loaded SchNet with 5704193 parameters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-04 08:51:51 (WARNING): Model gradient logging to tensorboard not yet supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-04 08:51:51 (INFO): Loading checkpoint from: ./checkpoints/2021-09-04-08-51-28-SchNet-example/checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "model = {\n",
    "    'name': 'schnet',\n",
    "    'hidden_channels': 1024, # if training is too slow for example purposes reduce the number of hidden channels\n",
    "    'num_filters': 256,\n",
    "    'num_interactions': 3,\n",
    "    'num_gaussians': 200,\n",
    "    'cutoff': 6.0\n",
    "}\n",
    "\n",
    "pretrained_trainer = ForcesTrainer(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    optimizer=optimizer,\n",
    "    identifier=\"SchNet-example\",\n",
    "    run_dir=\"./\", # directory to save results if is_debug=False. Prediction files are saved here so be careful not to override!\n",
    "    is_debug=False, # if True, do not save checkpoint, logs, or results\n",
    "    is_vis=False,\n",
    "    print_every=10,\n",
    "    seed=0, # random seed to use\n",
    "    logger=\"tensorboard\", # logger of choice (tensorboard and wandb supported)\n",
    "    local_rank=0,\n",
    "    amp=False, # use PyTorch Automatic Mixed Precision (faster training and less memory usage)\n",
    ")\n",
    "\n",
    "pretrained_trainer.load_checkpoint(checkpoint_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a test has been provided in your config, predictions are generated and written to disk automatically upon training completion. Otherwise, to make predictions on unseen data a `torch.utils.data` DataLoader object must be constructed. Here we reference our test set to make predictions on. Predictions are saved in `{results_file}.npz` in your `results_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-04 08:51:51 (INFO): Predicting on test.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "device 0: 100%|██████████| 79/79 [00:01<00:00, 44.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-04 08:51:53 (INFO): Writing results to ./results/2021-09-04-08-51-28-SchNet-example/s2ef_s2ef_results.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the existing test_loader\n",
    "predictions = pretrained_trainer.predict(pretrained_trainer.test_loader, results_file=\"s2ef_results\", disable_tqdm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = predictions[\"energy\"]\n",
    "forces = predictions[\"forces\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tio2-s2ef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
